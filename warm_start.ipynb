{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import setBoundaries, makeSamples, PhysicalLoss\n",
    "from glob import glob\n",
    "\n",
    "from networks import UNet, GrowingUNet, VariableLossUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def solve(initial, fixed, tol=1e-15, warm_start=None):\n",
    "    \"\"\"Simulate heat diffusion to identify the steady state.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    initial: float array\n",
    "      the initial temperate at every point in the grid\n",
    "    fixed: bool array\n",
    "      elements that are set to True will be kept fixed and not allowed to change\n",
    "    tol: float\n",
    "      iteration continues until no element changes by more than this\n",
    "    \"\"\"\n",
    "    mask = np.array([[0, 0.25, 0], [0.25, 0.0, 0.25], [0, 0.25, 0]])\n",
    "    fixed_values = initial[fixed]\n",
    "    width = initial.shape[0]\n",
    "    if warm_start is not None:\n",
    "        array = warm_start\n",
    "    else:\n",
    "        array = np.ones(initial.shape) * np.mean(fixed_values)\n",
    "\n",
    "    array[fixed] = fixed_values\n",
    "\n",
    "    # Iterate until convergence is reached.\n",
    "    iterations = 0\n",
    "    while True:\n",
    "        iterations += 1\n",
    "        new_array = convolve2d(array, mask, mode='same', boundary='symm')\n",
    "        new_array[fixed] = fixed_values\n",
    "        change = np.max(np.abs(array-new_array))\n",
    "        if change <= tol:\n",
    "            return array, iterations\n",
    "        array = new_array\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1; cuda=True; epoch_size=300; epochs=256; experiment='run256_grow_long'; growing=True\n",
    "image_size=256; learning_rate=0.0002; manualSeed=None; start_size=4\n",
    "\n",
    "# Set up CUDA\n",
    "if cuda and torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "    dtype = torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrowingUNet(\n",
      "  (encoding_layers): ModuleList(\n",
      "    (0): Conv2d (1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): Conv2d (256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (encoding_bns): ModuleList(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (decoding_layers): ModuleList(\n",
      "    (0): ConvTranspose2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (2): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ConvTranspose2d (1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ConvTranspose2d (512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ConvTranspose2d (256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): ConvTranspose2d (128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (decoding_bns): ModuleList(\n",
      "    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (stage_convs): ModuleList(\n",
      "  )\n",
      "  (stage_deconvs): ModuleList(\n",
      "  )\n",
      ")\n",
      "epoch [1/256], size 128, loss:0.5063\n",
      "epoch [2/256], size 128, loss:0.2542\n",
      "epoch [3/256], size 128, loss:0.2228\n",
      "epoch [4/256], size 128, loss:0.2036\n",
      "epoch [5/256], size 128, loss:0.1923\n",
      "epoch [6/256], size 128, loss:0.1951\n",
      "epoch [7/256], size 128, loss:0.1820\n",
      "epoch [8/256], size 128, loss:0.1695\n",
      "epoch [9/256], size 128, loss:0.1647\n",
      "epoch [10/256], size 128, loss:0.1564\n",
      "epoch [11/256], size 128, loss:0.1633\n",
      "epoch [12/256], size 128, loss:0.1650\n",
      "epoch [13/256], size 128, loss:0.1576\n",
      "epoch [14/256], size 128, loss:0.1585\n",
      "epoch [15/256], size 128, loss:0.1461\n",
      "epoch [16/256], size 128, loss:0.1552\n",
      "epoch [17/256], size 128, loss:0.1398\n",
      "epoch [18/256], size 128, loss:0.1471\n",
      "epoch [19/256], size 128, loss:0.1372\n",
      "epoch [20/256], size 128, loss:0.1438\n",
      "epoch [21/256], size 128, loss:0.1357\n",
      "epoch [22/256], size 128, loss:0.1393\n",
      "epoch [23/256], size 128, loss:0.1289\n",
      "epoch [24/256], size 128, loss:0.1232\n",
      "epoch [25/256], size 128, loss:0.1281\n",
      "epoch [26/256], size 128, loss:0.1355\n",
      "epoch [27/256], size 128, loss:0.1217\n",
      "epoch [28/256], size 128, loss:0.1161\n",
      "epoch [29/256], size 128, loss:0.1169\n",
      "epoch [30/256], size 128, loss:0.1154\n",
      "epoch [31/256], size 128, loss:0.1034\n",
      "epoch [32/256], size 128, loss:0.1037\n",
      "epoch [33/256], size 128, loss:0.1077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3b5056d72061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mmean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mmean_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         print('epoch [{}/{}], size {}, loss:{:.4f}'\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Make output directory\n",
    "# os.makedirs(experiment, exist_ok=True)\n",
    "\n",
    "\n",
    "# if not growing:\n",
    "#     start_size = image_size\n",
    "\n",
    "# net = GrowingUNet(dtype, image_size=image_size, start_size=start_size).type(dtype)\n",
    "# print(net)\n",
    "\n",
    "# physical_loss = PhysicalLoss(dtype)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# ## Outer training loop\n",
    "# size = start_size\n",
    "# epoch = 0\n",
    "# num_stages = int(np.log2(image_size) - np.log2(start_size)) + 1 if growing else 0\n",
    "# if num_stages >= 1:\n",
    "#     epochs = int(epochs*2**(-1*(num_stages-stage)))\n",
    "# stage = 0\n",
    "\n",
    "# while True:\n",
    "#     fixed_sample_0 = torch.zeros(1,1,size,size)\n",
    "#     fixed_sample_0[:,:,:,0] = 100\n",
    "#     fixed_sample_0[:,:,0,:] = 0\n",
    "#     fixed_sample_0[:,:,:,-1] = 100\n",
    "#     fixed_sample_0[:,:,-1,:] = 0\n",
    "#     fixed_sample_0 = Variable(fixed_sample_0).cuda()\n",
    "\n",
    "#     fixed_sample_1 = torch.zeros(1,1,size,size)\n",
    "#     fixed_sample_1[:,:,:,0] = 100\n",
    "#     fixed_sample_1[:,:,0,:] = 100\n",
    "#     fixed_sample_1[:,:,:,-1] = 100\n",
    "#     fixed_sample_1[:,:,-1,:] = 100\n",
    "#     fixed_sample_1 = Variable(fixed_sample_1).cuda()\n",
    "\n",
    "#     boundary = np.zeros((size, size), dtype=np.bool)\n",
    "#     boundary[0,:] = True\n",
    "#     boundary[-1,:] = True\n",
    "#     boundary[:,0] = True\n",
    "#     boundary[:,-1] = True\n",
    "\n",
    "#     fixed_solution_0 = solve(fixed_sample_0.cpu().data.numpy()[0,0,:,:], boundary, tol=1e-4)\n",
    "#     fixed_solution_1 = solve(fixed_sample_1.cpu().data.numpy()[0,0,:,:], boundary, tol=1e-4)\n",
    "\n",
    "#     ## Inner training loop\n",
    "#     data = torch.zeros(batch_size,1,size,size)\n",
    "#     #data = torch.zeros(batch_size,1,image_size,image_size)\n",
    "#     for _epoch in range(epochs):\n",
    "#         mean_loss = 0\n",
    "#         for sample in range(epoch_size):\n",
    "#             data[:,:,:,0] = np.random.uniform(100)\n",
    "#             data[:,:,0,:] = np.random.uniform(100)\n",
    "#             data[:,:,:,-1] = np.random.uniform(100)\n",
    "#             data[:,:,-1,:] = np.random.uniform(100)\n",
    "#             img = Variable(data).type(dtype)\n",
    "#             output = net(img)\n",
    "#             loss = physical_loss(output)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             mean_loss += loss.data[0]\n",
    "#         mean_loss /= epoch_size\n",
    "#         print('epoch [{}/{}], size {}, loss:{:.4f}'\n",
    "#               .format(epoch+1, epochs, size, mean_loss))\n",
    "#         epoch += 1\n",
    "\n",
    "#         # Plot real samples\n",
    "#         plt.figure(figsize=(20, 15))\n",
    "#         f_0 = net(fixed_sample_0)\n",
    "#         f_1 = net(fixed_sample_1)\n",
    "#         plt.subplot(2,2,1)\n",
    "#         plt.imshow(f_0.cpu().data.numpy()[0,0,:,:], vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "#         plt.axis('equal')\n",
    "#         plt.subplot(2,2,2)\n",
    "#         plt.imshow(f_1.cpu().data.numpy()[0,0,:,:], vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "#         plt.axis('equal')\n",
    "#         plt.subplot(2,2,3)\n",
    "#         plt.imshow(fixed_solution_0, vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "#         plt.axis('equal')\n",
    "#         plt.subplot(2,2,4)\n",
    "#         plt.imshow(fixed_solution_1, vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "#         plt.axis('equal')\n",
    "#         plt.savefig('%s/f_1_epoch%d.png' % (experiment, epoch))\n",
    "#         plt.close()\n",
    "\n",
    "#         # checkpoint networks\n",
    "#         if epoch % 50 == 0:\n",
    "#             torch.save(net.state_dict(), '%s/net_epoch_%d.pth' % (experiment, epoch))\n",
    "\n",
    "#         if epoch >= epochs:\n",
    "#             torch.save(net.state_dict(), '%s/net_epoch_%d.pth' % (experiment, epoch))\n",
    "#             exit()\n",
    "\n",
    "#     if size < image_size:\n",
    "#         size *= 2\n",
    "#         net.setSize(size)\n",
    "#         stage += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run256_grow_long/net_epoch_4095.pth\n",
      "GrowingUNet(\n",
      "  (encoding_layers): ModuleList(\n",
      "    (0): Conv2d (1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): Conv2d (256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): Conv2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (encoding_bns): ModuleList(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (decoding_layers): ModuleList(\n",
      "    (0): ConvTranspose2d (512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (2): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ConvTranspose2d (1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ConvTranspose2d (1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ConvTranspose2d (512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): ConvTranspose2d (256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ConvTranspose2d (128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (decoding_bns): ModuleList(\n",
      "    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (stage_convs): ModuleList(\n",
      "    (0): Conv2d (1, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d (1, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d (1, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d (1, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): Conv2d (1, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d (1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (stage_deconvs): ModuleList(\n",
      "    (0): Conv2d (512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d (512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d (512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d (256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): Conv2d (128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d (64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_test = 10\n",
    "\n",
    "files = glob(experiment+\"/*.pth\")\n",
    "maximum = 0\n",
    "for file in files:\n",
    "    maximum = max(int(file.split(\"_\")[-1].split(\".\")[0]), maximum)\n",
    "file = glob(experiment + \"/*\" + str(maximum) + \".pth\")[0]\n",
    "print(file)\n",
    "\n",
    "if not growing:\n",
    "    net = UNet(dtype, image_size=image_size).type(dtype)\n",
    "else:\n",
    "#     net = VariableLossUNet(dtype, image_size=image_size).type(dtype)\n",
    "    net = GrowingUNet(dtype, image_size=image_size, start_size=4).type(dtype)\n",
    "    net.setSize(image_size)\n",
    "state_dict = torch.load(file)\n",
    "# state_dict = torch.load(file, map_location=lambda storage, loc: storage.cuda(1))\n",
    "net.load_state_dict(state_dict)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm Start:  21575\n",
      "Finite Difference:  6640\n",
      "0 Error: 9.81, Loss: 0.01\n",
      "Warm Start:  13003\n",
      "Finite Difference:  7665\n",
      "1 Error: 6.57, Loss: 0.01\n",
      "Warm Start:  24656\n",
      "Finite Difference:  7457\n",
      "2 Error: 17.36, Loss: 0.01\n",
      "Warm Start:  16926\n",
      "Finite Difference:  8054\n",
      "3 Error: 6.64, Loss: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-80288db57401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warm Start: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-03230c39b0c3>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(initial, fixed, tol, warm_start)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mnew_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolve2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'symm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mnew_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfixed\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mchange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnew_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepPhysics/deepphys/lib/python3.5/site-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mconvolve2d\u001b[0;34m(in1, in2, mode, boundary, fillvalue)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;31m# FIXME: some cast generates a warning here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolve2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "physical_loss = PhysicalLoss(dtype)\n",
    "\n",
    "boundary = np.zeros((image_size, image_size), dtype=np.bool)\n",
    "boundary[0,:] = True\n",
    "boundary[-1,:] = True\n",
    "boundary[:,0] = True\n",
    "boundary[:,-1] = True\n",
    "\n",
    "data = torch.zeros(1,1,image_size,image_size)\n",
    "error = []\n",
    "for i in range(num_test):\n",
    "    data[:,:,:,0] = np.random.uniform(100)\n",
    "    data[:,:,0,:] = np.random.uniform(100)\n",
    "    data[:,:,:,-1] = np.random.uniform(100)\n",
    "    data[:,:,-1,:] = np.random.uniform(100)\n",
    "\n",
    "    img = Variable(data).type(dtype)\n",
    "    output = net(img)\n",
    "    loss = physical_loss(output)\n",
    "\n",
    "    output = output.cpu().data.numpy()[0,0,:,:]\n",
    "\n",
    "    solution, iterations = solve(data.cpu().numpy()[0,0,:,:], boundary, tol=1e-3, warm_start=output)\n",
    "    print(\"Warm Start: \", iterations)\n",
    "    solution, iterations = solve(data.cpu().numpy()[0,0,:,:], boundary, tol=1e-3)\n",
    "    print(\"Finite Difference: \", iterations)\n",
    "\n",
    "    error.append(np.mean(np.abs(output-solution))) \n",
    "    print(\"%d Error: %.2f, Loss: %.2f\" % (i, error[-1], loss.data[0]))\n",
    "    # Plot real samples\n",
    "    plt.figure(figsize=(15, 25))\n",
    "    XX, YY = np.meshgrid(np.arange(0, image_size), np.arange(0, image_size))\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.contourf(XX, YY, data.cpu().numpy()[0,0,:,:], colorinterpolation=50, vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "    plt.title(\"Initial Condition\")\n",
    "    plt.axis('equal')\n",
    "    plt.subplot(3,1,2)\n",
    "    plt.contourf(XX, YY, solution, colorinterpolation=50, vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "    plt.title(\"Equilibrium Condition\")\n",
    "    plt.axis('equal')\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.contourf(XX, YY, output, colorinterpolation=50, vmin=0, vmax=100, cmap=plt.cm.jet)\n",
    "    plt.title(\"Learned Output\")\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('%s/test_%d.png' % (experiment, i))\n",
    "    plt.close()\n",
    "\n",
    "error = np.array(error)\n",
    "print(\"error: \", np.mean(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
